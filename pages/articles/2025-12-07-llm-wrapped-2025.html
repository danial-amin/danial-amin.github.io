<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Wrapped 2025 - Danial Amin</title>
    <meta name="description" content="A data-driven look at language model development and deployment across 2025.">
    <meta name="author" content="Danial Amin">
    
    <link rel="stylesheet" href="../../css/style.css">
    <link rel="stylesheet" href="../../css/themes.css">
    <link rel="stylesheet" href="../../css/animations.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap" rel="stylesheet">
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            overflow-x: hidden;
            background: var(--bg-primary);
            color: var(--text-primary);
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
        }

        .wrapped-container {
            position: relative;
            width: 100vw;
        }

        .slide {
            position: relative;
            width: 100%;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 6rem 2rem 4rem;
            overflow: visible;
        }

        .slide-content {
            max-width: 1200px;
            width: 100%;
            text-align: center;
            position: relative;
            z-index: 2;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 2rem 0;
            overflow: visible;
            box-sizing: border-box;
        }
        
        /* Ensure content fits within viewport but can expand if needed */
        .slide-content > * {
            max-width: 100%;
            box-sizing: border-box;
        }

        /* Theme-based backgrounds with animated gradients */
        .slide {
            background: var(--bg-primary);
            position: relative;
            overflow: hidden;
        }
        
        /* Base animated gradient layer */
        .slide::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            z-index: 0;
            pointer-events: none;
        }
        
        /* Secondary animated layer */
        .slide::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            z-index: 0;
            pointer-events: none;
        }
        
        /* Slide 1: Rotating radial gradient */
        .slide-1::before {
            background: radial-gradient(circle at 30% 50%, 
                var(--accent-color) 0%, 
                transparent 50%);
            opacity: 0.15;
            animation: rotateRadial 20s linear infinite;
        }
        
        .slide-1::after {
            background: radial-gradient(circle at 70% 50%, 
                var(--secondary-accent) 0%, 
                transparent 50%);
            opacity: 0.1;
            animation: rotateRadial 25s linear infinite reverse;
        }
        
        @keyframes rotateRadial {
            0% { transform: rotate(0deg) scale(1); }
            50% { transform: rotate(180deg) scale(1.2); }
            100% { transform: rotate(360deg) scale(1); }
        }
        
        /* Slide 2: Wave animation */
        .slide-2::before {
            background: linear-gradient(135deg, 
                var(--accent-color) 0%, 
                var(--secondary-accent) 50%,
                var(--accent-color) 100%);
            opacity: 0.1;
            animation: waveMove 8s ease-in-out infinite;
        }
        
        .slide-2::after {
            background: linear-gradient(225deg, 
                var(--secondary-accent) 0%, 
                var(--accent-color) 50%,
                var(--secondary-accent) 100%);
            opacity: 0.08;
            animation: waveMove 10s ease-in-out infinite reverse;
        }
        
        @keyframes waveMove {
            0%, 100% { 
                transform: translateX(0) translateY(0) scale(1);
                opacity: 0.1;
            }
            50% { 
                transform: translateX(50px) translateY(-30px) scale(1.1);
                opacity: 0.15;
            }
        }
        
        /* Slide 3: Orbiting gradients */
        .slide-3::before {
            background: radial-gradient(circle at 20% 30%, 
                var(--accent-color) 0%, 
                transparent 40%);
            opacity: 0.12;
            animation: orbit1 15s ease-in-out infinite;
        }
        
        .slide-3::after {
            background: radial-gradient(circle at 80% 70%, 
                var(--secondary-accent) 0%, 
                transparent 40%);
            opacity: 0.1;
            animation: orbit2 18s ease-in-out infinite;
        }
        
        @keyframes orbit1 {
            0%, 100% { transform: translate(0, 0) scale(1); }
            25% { transform: translate(100px, -50px) scale(1.2); }
            50% { transform: translate(50px, -100px) scale(1); }
            75% { transform: translate(-50px, -50px) scale(1.1); }
        }
        
        @keyframes orbit2 {
            0%, 100% { transform: translate(0, 0) scale(1); }
            25% { transform: translate(-80px, 60px) scale(1.1); }
            50% { transform: translate(-40px, 100px) scale(1.2); }
            75% { transform: translate(60px, 40px) scale(1); }
        }
        
        /* Slide 4: Pulsing mesh */
        .slide-4::before {
            background: 
                radial-gradient(circle at 25% 25%, var(--accent-color) 0%, transparent 25%),
                radial-gradient(circle at 75% 75%, var(--secondary-accent) 0%, transparent 25%);
            opacity: 0.1;
            animation: pulseMesh 6s ease-in-out infinite;
        }
        
        .slide-4::after {
            background: 
                radial-gradient(circle at 75% 25%, var(--secondary-accent) 0%, transparent 30%),
                radial-gradient(circle at 25% 75%, var(--accent-color) 0%, transparent 30%);
            opacity: 0.08;
            animation: pulseMesh 8s ease-in-out infinite reverse;
        }
        
        @keyframes pulseMesh {
            0%, 100% { 
                transform: scale(1);
                opacity: 0.1;
            }
            50% { 
                transform: scale(1.3);
                opacity: 0.15;
            }
        }
        
        /* Slide 5: Flowing gradient */
        .slide-5::before {
            background: linear-gradient(45deg, 
                var(--accent-color) 0%, 
                transparent 30%,
                var(--secondary-accent) 60%,
                transparent 100%);
            opacity: 0.12;
            animation: flowGradient 12s linear infinite;
        }
        
        .slide-5::after {
            background: linear-gradient(225deg, 
                var(--secondary-accent) 0%, 
                transparent 40%,
                var(--accent-color) 70%,
                transparent 100%);
            opacity: 0.1;
            animation: flowGradient 15s linear infinite reverse;
        }
        
        @keyframes flowGradient {
            0% { transform: translateX(-100%) translateY(-100%) rotate(0deg); }
            100% { transform: translateX(100%) translateY(100%) rotate(360deg); }
        }
        
        /* Slide 6: Spiral gradient */
        .slide-6::before {
            background: conic-gradient(from 0deg at 50% 50%, 
                var(--accent-color) 0deg, 
                transparent 60deg,
                var(--secondary-accent) 120deg,
                transparent 180deg,
                var(--accent-color) 240deg,
                transparent 300deg,
                var(--secondary-accent) 360deg);
            opacity: 0.1;
            animation: spinSpiral 20s linear infinite;
        }
        
        .slide-6::after {
            background: conic-gradient(from 180deg at 50% 50%, 
                var(--secondary-accent) 0deg, 
                transparent 90deg,
                var(--accent-color) 180deg,
                transparent 270deg,
                var(--secondary-accent) 360deg);
            opacity: 0.08;
            animation: spinSpiral 25s linear infinite reverse;
        }
        
        @keyframes spinSpiral {
            0% { transform: rotate(0deg) scale(1); }
            100% { transform: rotate(360deg) scale(1.1); }
        }
        
        /* Slide 7: Expanding circles */
        .slide-7::before {
            background: radial-gradient(circle, 
                var(--accent-color) 0%, 
                transparent 30%);
            opacity: 0.12;
            animation: expandCircle 10s ease-in-out infinite;
        }
        
        .slide-7::after {
            background: radial-gradient(circle, 
                var(--secondary-accent) 0%, 
                transparent 35%);
            opacity: 0.1;
            animation: expandCircle 12s ease-in-out infinite reverse;
        }
        
        @keyframes expandCircle {
            0%, 100% { 
                transform: scale(0.8);
                opacity: 0.12;
            }
            50% { 
                transform: scale(1.5);
                opacity: 0.08;
            }
        }
        
        /* Slide 8: Diagonal sweep */
        .slide-8::before {
            background: linear-gradient(135deg, 
                transparent 0%,
                var(--accent-color) 30%,
                var(--secondary-accent) 50%,
                var(--accent-color) 70%,
                transparent 100%);
            opacity: 0.1;
            animation: diagonalSweep 9s ease-in-out infinite;
        }
        
        .slide-8::after {
            background: linear-gradient(315deg, 
                transparent 0%,
                var(--secondary-accent) 25%,
                var(--accent-color) 55%,
                var(--secondary-accent) 75%,
                transparent 100%);
            opacity: 0.08;
            animation: diagonalSweep 11s ease-in-out infinite reverse;
        }
        
        @keyframes diagonalSweep {
            0%, 100% { 
                transform: translateX(-50%) translateY(-50%) rotate(0deg);
            }
            50% { 
                transform: translateX(50%) translateY(50%) rotate(180deg);
            }
        }
        
        /* Slide 9: Ripple effect */
        .slide-9::before {
            background: radial-gradient(circle at 50% 50%, 
                var(--accent-color) 0%, 
                transparent 40%);
            opacity: 0.1;
            animation: ripple 8s ease-out infinite;
        }
        
        .slide-9::after {
            background: radial-gradient(circle at 50% 50%, 
                var(--secondary-accent) 0%, 
                transparent 45%);
            opacity: 0.08;
            animation: ripple 10s ease-out infinite 2s;
        }
        
        @keyframes ripple {
            0% { 
                transform: scale(0.5);
                opacity: 0.1;
            }
            50% { 
                transform: scale(1.2);
                opacity: 0.15;
            }
            100% { 
                transform: scale(2);
                opacity: 0;
            }
        }
        
        /* Slide 10: Zigzag pattern */
        .slide-10::before {
            background: 
                repeating-linear-gradient(45deg, 
                    var(--accent-color) 0px,
                    transparent 20px,
                    var(--secondary-accent) 40px,
                    transparent 60px);
            opacity: 0.08;
            animation: zigzag 12s linear infinite;
        }
        
        .slide-10::after {
            background: 
                repeating-linear-gradient(-45deg, 
                    var(--secondary-accent) 0px,
                    transparent 25px,
                    var(--accent-color) 50px,
                    transparent 75px);
            opacity: 0.06;
            animation: zigzag 15s linear infinite reverse;
        }
        
        @keyframes zigzag {
            0% { transform: translateX(0) translateY(0); }
            100% { transform: translateX(200px) translateY(200px); }
        }
        
        /* Slide 11: Concentric circles */
        .slide-11::before {
            background: 
                radial-gradient(circle, var(--accent-color) 0%, transparent 20%),
                radial-gradient(circle, transparent 25%, var(--secondary-accent) 30%, transparent 40%);
            opacity: 0.1;
            animation: concentric 14s ease-in-out infinite;
        }
        
        .slide-11::after {
            background: 
                radial-gradient(circle, var(--secondary-accent) 0%, transparent 22%),
                radial-gradient(circle, transparent 28%, var(--accent-color) 35%, transparent 45%);
            opacity: 0.08;
            animation: concentric 16s ease-in-out infinite reverse;
        }
        
        @keyframes concentric {
            0%, 100% { transform: scale(1) rotate(0deg); }
            50% { transform: scale(1.2) rotate(180deg); }
        }
        
        /* Slide 12: Shimmer effect */
        .slide-12::before {
            background: linear-gradient(90deg, 
                transparent 0%,
                var(--accent-color) 25%,
                var(--secondary-accent) 50%,
                var(--accent-color) 75%,
                transparent 100%);
            opacity: 0.1;
            animation: shimmer 7s linear infinite;
        }
        
        .slide-12::after {
            background: linear-gradient(90deg, 
                transparent 0%,
                var(--secondary-accent) 30%,
                var(--accent-color) 60%,
                var(--secondary-accent) 80%,
                transparent 100%);
            opacity: 0.08;
            animation: shimmer 9s linear infinite reverse;
        }
        
        @keyframes shimmer {
            0% { transform: translateX(-100%) skewX(-20deg); }
            100% { transform: translateX(200%) skewX(-20deg); }
        }
        
        /* Slide 13: Bubble effect */
        .slide-13::before {
            background: 
                radial-gradient(circle at 20% 20%, var(--accent-color) 0%, transparent 25%),
                radial-gradient(circle at 80% 80%, var(--secondary-accent) 0%, transparent 30%);
            opacity: 0.1;
            animation: bubbleFloat 11s ease-in-out infinite;
        }
        
        .slide-13::after {
            background: 
                radial-gradient(circle at 60% 30%, var(--secondary-accent) 0%, transparent 28%),
                radial-gradient(circle at 40% 70%, var(--accent-color) 0%, transparent 32%);
            opacity: 0.08;
            animation: bubbleFloat 13s ease-in-out infinite reverse;
        }
        
        @keyframes bubbleFloat {
            0%, 100% { transform: translateY(0) scale(1); }
            33% { transform: translateY(-30px) scale(1.1); }
            66% { transform: translateY(20px) scale(0.9); }
        }
        
        /* Slide 14: Grid pulse */
        .slide-14::before {
            background: 
                linear-gradient(var(--accent-color) 1px, transparent 1px),
                linear-gradient(90deg, var(--accent-color) 1px, transparent 1px);
            background-size: 50px 50px;
            opacity: 0.08;
            animation: gridPulse 8s ease-in-out infinite;
        }
        
        .slide-14::after {
            background: 
                linear-gradient(var(--secondary-accent) 1px, transparent 1px),
                linear-gradient(90deg, var(--secondary-accent) 1px, transparent 1px);
            background-size: 60px 60px;
            opacity: 0.06;
            animation: gridPulse 10s ease-in-out infinite reverse;
        }
        
        @keyframes gridPulse {
            0%, 100% { 
                transform: scale(1);
                opacity: 0.08;
            }
            50% { 
                transform: scale(1.1);
                opacity: 0.12;
            }
        }
        
        /* Slide 15: Starfield */
        .slide-15::before {
            background: 
                radial-gradient(2px 2px at 20% 30%, var(--accent-color), transparent),
                radial-gradient(2px 2px at 60% 70%, var(--secondary-accent), transparent),
                radial-gradient(1px 1px at 50% 50%, var(--accent-color), transparent);
            background-size: 200px 200px;
            opacity: 0.1;
            animation: starfield 20s linear infinite;
        }
        
        .slide-15::after {
            background: 
                radial-gradient(2px 2px at 80% 20%, var(--secondary-accent), transparent),
                radial-gradient(2px 2px at 40% 80%, var(--accent-color), transparent),
                radial-gradient(1px 1px at 30% 60%, var(--secondary-accent), transparent);
            background-size: 250px 250px;
            opacity: 0.08;
            animation: starfield 25s linear infinite reverse;
        }
        
        @keyframes starfield {
            0% { transform: translate(0, 0) rotate(0deg); }
            100% { transform: translate(100px, 100px) rotate(360deg); }
        }
        
        /* Slide 16: Morphing blob */
        .slide-16::before {
            background: radial-gradient(ellipse at 30% 50%, 
                var(--accent-color) 0%, 
                transparent 50%);
            opacity: 0.12;
            animation: morphBlob 12s ease-in-out infinite;
        }
        
        .slide-16::after {
            background: radial-gradient(ellipse at 70% 50%, 
                var(--secondary-accent) 0%, 
                transparent 55%);
            opacity: 0.1;
            animation: morphBlob 14s ease-in-out infinite reverse;
        }
        
        @keyframes morphBlob {
            0%, 100% { 
                border-radius: 60% 40% 30% 70% / 60% 30% 70% 40%;
                transform: scale(1) rotate(0deg);
            }
            50% { 
                border-radius: 30% 60% 70% 40% / 50% 60% 30% 60%;
                transform: scale(1.2) rotate(180deg);
            }
        }
        
        /* Slide 17: Kaleidoscope */
        .slide-17::before {
            background: conic-gradient(from 0deg, 
                var(--accent-color) 0deg 60deg,
                var(--secondary-accent) 60deg 120deg,
                var(--accent-color) 120deg 180deg,
                var(--secondary-accent) 180deg 240deg,
                var(--accent-color) 240deg 300deg,
                var(--secondary-accent) 300deg 360deg);
            opacity: 0.1;
            animation: kaleidoscope 16s linear infinite;
        }
        
        .slide-17::after {
            background: conic-gradient(from 180deg, 
                var(--secondary-accent) 0deg 45deg,
                var(--accent-color) 45deg 90deg,
                var(--secondary-accent) 90deg 135deg,
                var(--accent-color) 135deg 180deg,
                var(--secondary-accent) 180deg 225deg,
                var(--accent-color) 225deg 270deg,
                var(--secondary-accent) 270deg 315deg,
                var(--accent-color) 315deg 360deg);
            opacity: 0.08;
            animation: kaleidoscope 18s linear infinite reverse;
        }
        
        @keyframes kaleidoscope {
            0% { transform: rotate(0deg) scale(1); }
            100% { transform: rotate(360deg) scale(1.1); }
        }
        
        /* Slide 18: Liquid motion */
        .slide-18::before {
            background: 
                radial-gradient(ellipse 800px 400px at 30% 50%, var(--accent-color), transparent),
                radial-gradient(ellipse 600px 500px at 70% 50%, var(--secondary-accent), transparent);
            opacity: 0.1;
            animation: liquidMotion 10s ease-in-out infinite;
        }
        
        .slide-18::after {
            background: 
                radial-gradient(ellipse 700px 450px at 50% 30%, var(--secondary-accent), transparent),
                radial-gradient(ellipse 500px 600px at 50% 70%, var(--accent-color), transparent);
            opacity: 0.08;
            animation: liquidMotion 12s ease-in-out infinite reverse;
        }
        
        @keyframes liquidMotion {
            0%, 100% { 
                transform: translateX(0) translateY(0) scale(1);
            }
            33% { 
                transform: translateX(50px) translateY(-30px) scale(1.1);
            }
            66% { 
                transform: translateX(-30px) translateY(40px) scale(0.9);
            }
        }
        
        /* Slide 19: Aurora effect */
        .slide-19::before {
            background: 
                linear-gradient(180deg, 
                    transparent 0%,
                    var(--accent-color) 20%,
                    var(--secondary-accent) 40%,
                    var(--accent-color) 60%,
                    transparent 100%);
            opacity: 0.12;
            animation: aurora 9s ease-in-out infinite;
        }
        
        .slide-19::after {
            background: 
                linear-gradient(180deg, 
                    transparent 0%,
                    var(--secondary-accent) 25%,
                    var(--accent-color) 45%,
                    var(--secondary-accent) 65%,
                    transparent 100%);
            opacity: 0.1;
            animation: aurora 11s ease-in-out infinite reverse;
        }
        
        @keyframes aurora {
            0%, 100% { 
                transform: translateY(0) scaleY(1);
                opacity: 0.12;
            }
            50% { 
                transform: translateY(-20px) scaleY(1.2);
                opacity: 0.15;
            }
        }
        
        /* Slide 20: Final celebration */
        .slide-20::before {
            background: 
                radial-gradient(circle at 25% 25%, var(--accent-color) 0%, transparent 30%),
                radial-gradient(circle at 75% 75%, var(--secondary-accent) 0%, transparent 35%),
                radial-gradient(circle at 50% 50%, var(--accent-color) 0%, transparent 40%);
            opacity: 0.12;
            animation: celebration 8s ease-in-out infinite;
        }
        
        .slide-20::after {
            background: 
                radial-gradient(circle at 75% 25%, var(--secondary-accent) 0%, transparent 32%),
                radial-gradient(circle at 25% 75%, var(--accent-color) 0%, transparent 38%),
                radial-gradient(circle at 50% 50%, var(--secondary-accent) 0%, transparent 42%);
            opacity: 0.1;
            animation: celebration 10s ease-in-out infinite reverse;
        }
        
        @keyframes celebration {
            0%, 100% { 
                transform: scale(1) rotate(0deg);
                opacity: 0.12;
            }
            25% { 
                transform: scale(1.1) rotate(90deg);
                opacity: 0.15;
            }
            50% { 
                transform: scale(1.2) rotate(180deg);
                opacity: 0.12;
            }
            75% { 
                transform: scale(1.1) rotate(270deg);
                opacity: 0.15;
            }
        }
        
        /* References Section */
        .references-section {
            background: var(--bg-primary);
            position: relative;
            overflow: hidden;
            padding: 6rem 2rem 4rem;
            min-height: 100vh;
        }
        
        .references-section::before {
            background: linear-gradient(135deg, 
                var(--accent-color) 0%, 
                var(--secondary-accent) 50%,
                var(--accent-color) 100%);
            opacity: 0.05;
            animation: gradientShift 12s ease infinite;
        }
        
        .references-content {
            max-width: 1000px;
            width: 100%;
            margin: 0 auto;
            position: relative;
            z-index: 2;
        }
        
        .references-title {
            font-size: clamp(1.2rem, 3vw, 1.8rem);
            font-weight: 900;
            color: var(--text-primary);
            margin-bottom: 2rem;
            text-align: center;
            text-shadow: 0 2px 10px var(--shadow-accent);
        }
        
        .references-category {
            margin-bottom: 2rem;
        }
        
        .category-title {
            font-size: clamp(0.95rem, 1.6vw, 1.15rem);
            font-weight: 700;
            color: var(--accent-color);
            margin-bottom: 1rem;
            padding-bottom: 0.4rem;
            border-bottom: 2px solid var(--border-color);
        }
        
        .reference-item {
            background: var(--card-bg);
            backdrop-filter: blur(20px);
            border-radius: 12px;
            padding: 1rem;
            margin-bottom: 1rem;
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-small);
            transition: all 0.3s ease;
            position: relative;
            z-index: 1;
        }
        
        .reference-item:hover {
            transform: translateX(5px);
            border-color: var(--accent-color);
            box-shadow: var(--shadow-medium);
        }
        
        .reference-source {
            font-weight: 600;
            color: var(--text-primary);
            font-size: clamp(0.8rem, 1.1vw, 0.9rem);
            margin-bottom: 0.3rem;
            line-height: 1.4;
        }
        
        .reference-link {
            color: var(--accent-color);
            text-decoration: none;
            font-size: clamp(0.7rem, 0.9vw, 0.8rem);
            word-break: break-all;
            display: block;
            margin-top: 0.3rem;
            transition: color 0.3s ease;
        }
        
        .reference-link:hover {
            color: var(--secondary-accent);
            text-decoration: underline;
        }
        
        .reference-details {
            color: var(--text-secondary);
            font-size: clamp(0.75rem, 0.95vw, 0.85rem);
            line-height: 1.5;
            margin-top: 0.5rem;
        }
        
        .reference-key-data {
            margin-top: 0.5rem;
            padding-top: 0.5rem;
            border-top: 1px solid var(--border-color);
            color: var(--text-secondary);
            font-size: clamp(0.7rem, 0.9vw, 0.8rem);
            font-style: italic;
        }
        
        .reference-note {
            background: var(--card-bg);
            backdrop-filter: blur(20px);
            border-radius: 12px;
            padding: 1.2rem;
            margin-top: 2rem;
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-medium);
            position: relative;
            z-index: 1;
        }
        
        .reference-note-title {
            font-size: clamp(0.9rem, 1.4vw, 1.05rem);
            font-weight: 700;
            color: var(--accent-color);
            margin-bottom: 0.6rem;
        }
        
        .reference-note-text {
            color: var(--text-secondary);
            font-size: clamp(0.75rem, 1vw, 0.85rem);
            line-height: 1.6;
        }

        .slide-title {
            font-size: clamp(2rem, 6vw, 4.5rem);
            font-weight: 900;
            margin-bottom: 1rem;
            color: var(--text-primary);
            text-shadow: 0 2px 10px var(--shadow-accent);
            line-height: 1.2;
            word-wrap: break-word;
            overflow-wrap: break-word;
            position: relative;
            z-index: 1;
        }

        .slide-subtitle {
            font-size: clamp(1rem, 2.5vw, 1.8rem);
            font-weight: 600;
            margin-bottom: 1.5rem;
            color: var(--accent-color);
            line-height: 1.3;
            word-wrap: break-word;
            position: relative;
            z-index: 1;
        }

        .slide-description {
            font-size: clamp(0.9rem, 1.8vw, 1.2rem);
            line-height: 1.6;
            color: var(--text-secondary);
            max-width: 900px;
            margin: 0 auto 1.5rem;
            word-wrap: break-word;
            overflow-wrap: break-word;
            position: relative;
            z-index: 1;
        }

        /* Stats Cards */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
            width: 100%;
            max-width: 100%;
        }

        .stat-card {
            background: var(--card-bg);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
            box-shadow: var(--shadow-medium);
            transition: all 0.3s ease;
            min-height: 0;
            display: flex;
            flex-direction: column;
            justify-content: center;
            overflow: hidden;
            word-wrap: break-word;
            position: relative;
            z-index: 1;
        }
        
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: var(--shadow-large);
            border-color: var(--accent-color);
        }

        .stat-number {
            font-size: clamp(2rem, 5vw, 3.5rem);
            font-weight: 900;
            color: var(--accent-color);
            margin-bottom: 0.5rem;
            text-shadow: 0 2px 10px var(--shadow-accent);
            line-height: 1.1;
            word-wrap: break-word;
        }

        .stat-label {
            font-size: clamp(0.85rem, 1.3vw, 1rem);
            color: var(--text-secondary);
            font-weight: 500;
            line-height: 1.4;
            word-wrap: break-word;
        }

        /* List Items */
        .feature-list {
            list-style: none;
            text-align: left;
            max-width: 800px;
            margin: 1.5rem auto;
            width: 100%;
            max-width: 100%;
            box-sizing: border-box;
        }

        .feature-item {
            background: var(--card-bg);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 1.2rem;
            margin-bottom: 0.8rem;
            border: 1px solid var(--border-color);
            border-left: 4px solid var(--accent-color);
            transition: all 0.3s ease;
            overflow: hidden;
            word-wrap: break-word;
            position: relative;
            z-index: 1;
        }
        
        .feature-item:hover {
            transform: translateX(5px);
            border-color: var(--accent-color);
            box-shadow: var(--shadow-medium);
        }

        .feature-item strong {
            color: var(--text-primary);
            font-size: clamp(1rem, 1.5vw, 1.2rem);
            display: block;
            margin-bottom: 0.4rem;
            line-height: 1.3;
            word-wrap: break-word;
        }

        .feature-item p {
            color: var(--text-secondary);
            line-height: 1.5;
            font-size: clamp(0.85rem, 1.2vw, 1rem);
            word-wrap: break-word;
        }

        /* Timeline - Horizontal layout for slide 3 */
        .timeline {
            position: relative;
            max-width: 1200px;
            margin: 2rem auto;
            width: 100%;
            max-width: 100%;
            box-sizing: border-box;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
        }

        .timeline-item {
            background: var(--card-bg);
            backdrop-filter: blur(20px);
            border-radius: 15px;
            padding: 1.5rem;
            border: 1px solid var(--border-color);
            border-left: 4px solid var(--accent-color);
            overflow: hidden;
            word-wrap: break-word;
            box-shadow: var(--shadow-medium);
            transition: all 0.3s ease;
            position: relative;
            z-index: 1;
        }
        
        .timeline-item:hover {
            transform: translateY(-5px);
            box-shadow: var(--shadow-large);
            border-color: var(--accent-color);
        }

        .timeline-period {
            font-size: clamp(1.1rem, 2vw, 1.4rem);
            font-weight: 700;
            color: var(--accent-color);
            margin-bottom: 0.8rem;
            line-height: 1.3;
            word-wrap: break-word;
        }

        .timeline-content {
            color: var(--text-secondary);
            line-height: 1.6;
            font-size: clamp(0.9rem, 1.3vw, 1.1rem);
            word-wrap: break-word;
        }
        
        .timeline-content strong {
            color: var(--text-primary);
        }

        /* Progress Bar */
        .progress-container {
            max-width: 700px;
            margin: 1.5rem auto;
            width: 100%;
            max-width: 100%;
            box-sizing: border-box;
        }

        .progress-bar-wrapper {
            background: var(--input-bg);
            border-radius: 50px;
            height: 35px;
            overflow: hidden;
            margin-bottom: 1rem;
            position: relative;
            border: 1px solid var(--border-color);
        }

        .progress-bar {
            height: 100%;
            background: linear-gradient(90deg, var(--accent-color), var(--secondary-accent));
            border-radius: 50px;
            width: 0;
            transition: width 1.5s ease-out;
            box-shadow: 0 0 20px var(--shadow-accent);
        }

        .progress-label {
            color: var(--text-primary);
            font-weight: 600;
            font-size: clamp(0.95rem, 1.5vw, 1.1rem);
            margin-bottom: 0.5rem;
            word-wrap: break-word;
            position: relative;
            z-index: 1;
        }

        /* Scroll Progress Indicator */
        .scroll-progress {
            position: fixed;
            top: 0;
            left: 0;
            height: 4px;
            background: var(--accent-color);
            z-index: 10000;
            width: 0%;
            transition: width 0.1s ease-out;
            box-shadow: 0 0 10px var(--shadow-accent);
        }

        /* Floating animated particles */
        .slide-particle {
            position: absolute;
            border-radius: 50%;
            pointer-events: none;
            z-index: 1;
            opacity: 0.4;
        }
        
        .particle-1 {
            width: 4px;
            height: 4px;
            background: var(--accent-color);
            box-shadow: 0 0 6px var(--accent-color);
            animation: float1 15s ease-in-out infinite;
        }
        
        .particle-2 {
            width: 6px;
            height: 6px;
            background: var(--secondary-accent);
            box-shadow: 0 0 8px var(--secondary-accent);
            animation: float2 18s ease-in-out infinite;
        }
        
        .particle-3 {
            width: 3px;
            height: 3px;
            background: var(--accent-color);
            box-shadow: 0 0 4px var(--accent-color);
            animation: float3 12s ease-in-out infinite;
        }
        
        @keyframes float1 {
            0%, 100% { 
                transform: translate(0, 0) scale(1);
                opacity: 0.4;
            }
            25% { 
                transform: translate(100px, -80px) scale(1.2);
                opacity: 0.6;
            }
            50% { 
                transform: translate(200px, -50px) scale(0.8);
                opacity: 0.3;
            }
            75% { 
                transform: translate(100px, 50px) scale(1.1);
                opacity: 0.5;
            }
        }
        
        @keyframes float2 {
            0%, 100% { 
                transform: translate(0, 0) scale(1);
                opacity: 0.3;
            }
            33% { 
                transform: translate(-120px, 100px) scale(1.3);
                opacity: 0.5;
            }
            66% { 
                transform: translate(-200px, 30px) scale(0.7);
                opacity: 0.2;
            }
        }
        
        @keyframes float3 {
            0%, 100% { 
                transform: translate(0, 0) scale(1);
                opacity: 0.5;
            }
            50% { 
                transform: translate(150px, 120px) scale(1.4);
                opacity: 0.7;
            }
        }


        /* Number Counter Animation */
        .counter {
            display: inline-block;
            font-weight: 900;
        }

        /* Responsive */
        @media (max-width: 768px) {
            .slide {
                padding: 2rem 1rem;
            }
            
            .slide-content {
                min-height: calc(100vh - 4rem);
                padding: 1rem 0;
            }
            
            .stats-grid {
                grid-template-columns: 1fr;
                gap: 1rem;
            }
            
            .stat-card {
                padding: 1.2rem;
            }
            
            .feature-item {
                padding: 1rem;
            }
            
            .timeline-item {
                padding: 1.2rem;
            }
        }
        
        @media (max-height: 700px) {
            .slide-content {
                padding: 0.5rem 0;
            }
            
            .slide-title {
                margin-bottom: 0.5rem;
            }
            
            .slide-subtitle {
                margin-bottom: 1rem;
            }
            
            .stats-grid {
                gap: 1rem;
                margin: 1rem 0;
            }
            
            .feature-list {
                margin: 1rem auto;
            }
            
            .feature-item {
                padding: 0.8rem;
                margin-bottom: 0.5rem;
            }
        }

        /* Special Effects */
        .glow-text {
            text-shadow: 0 0 20px var(--shadow-accent),
                         0 0 40px var(--shadow-accent),
                         0 0 60px var(--shadow-accent);
            color: var(--accent-color);
        }

        .pulse {
            animation: pulse 2s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.05);
            }
        }
    </style>
</head>
<body data-theme="dark">
    <!-- Interactive Background -->
    <canvas id="interactive-bg"></canvas>
    
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-brand">
                <a href="../../index.html">Danial Amin</a>
            </div>
            <div class="nav-menu">
                <a href="../../index.html" class="nav-link">Home</a>
                <a href="../projects.html" class="nav-link">Projects</a>
                <a href="../blog.html" class="nav-link active">Blog</a>
                <a href="../../index.html#contact" class="nav-link">Contact</a>
                <button class="theme-toggle" id="theme-toggle">
                    <span class="theme-icon">ðŸŒ™</span>
                </button>
            </div>
            <div class="hamburger" id="hamburger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
    </nav>
    
    <div class="scroll-progress" id="scrollProgress"></div>
    <div class="wrapped-container" id="wrappedContainer">
        <!-- Slide 1: Introduction -->
        <div class="slide slide-1" data-slide="1">
            <div class="slide-content">
                <h1 class="slide-title glow-text">LLM Wrapped</h1>
                <h2 class="slide-subtitle">2025</h2>
                <p class="slide-description">A data-driven look at language model development and deployment across the year.</p>
            </div>
        </div>

        <!-- Slide 2: Agentic AI Adoption -->
        <div class="slide slide-2" data-slide="2">
            <div class="slide-content">
                <h1 class="slide-title">The Enterprise Shift</h1>
                <p class="slide-description">While industry discourse proclaimed 2025 "the year of the agent," actual deployment tells a more measured story.</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="99">0</span>%</div>
                        <div class="stat-label">of enterprise developers exploring AI agents</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="62">0</span>%</div>
                        <div class="stat-label">of organizations experimenting</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="23">0</span>%</div>
                        <div class="stat-label">scaling agents in production</div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">The gap between experimentation and production-scale deployment remained significant.</p>
            </div>
        </div>

        <!-- Slide 3: Major Model Releases -->
        <div class="slide slide-3" data-slide="3">
            <div class="slide-content">
                <h1 class="slide-title">Frontier Model Evolution</h1>
                <p class="slide-description">2025 saw continued investment in large-scale models</p>
                <div class="timeline">
                    <div class="timeline-item">
                        <div class="timeline-period">Q1-Q2 2025</div>
                        <div class="timeline-content">
                            <strong>Claude Sonnet 3.7</strong> (February) - First agent-oriented LLM<br>
                            <strong>Gemini 2.5 Pro</strong> (March) - Deep Think reasoning mode<br>
                            <strong>DeepSeek V3.1</strong> (March) - Hybrid thinking/non-thinking architecture
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-period">Q2-Q3 2025</div>
                        <div class="timeline-content">
                            <strong>Claude Sonnet 4 & Opus 4</strong> (May) - Tool use, extended thinking<br>
                            <strong>Llama 4</strong> (April) - Multimodal with 10M token context<br>
                            <strong>GPT-5</strong> (August) - Model routing, specialized thinking variants<br>
                            <strong>Grok 4</strong> (July) - Competitive benchmark performance
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-period">Q4 2025</div>
                        <div class="timeline-content">
                            <strong>Gemini 3 Pro</strong> (November) - Replaced Ultra tier<br>
                            <strong>GPT 5.1</strong> (November)<br>
                            <strong>Claude Sonnet 4.5 & Opus 4.5</strong> (December)
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 4: Code Generation Market -->
        <div class="slide slide-4" data-slide="4">
            <div class="slide-content">
                <h1 class="slide-title">First Measurable Killer App</h1>
                <p class="slide-description">Code generation emerged as AI's first demonstrable commercial success.</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="42">0</span>%</div>
                        <div class="stat-label">Claude market share</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="21">0</span>%</div>
                        <div class="stat-label">OpenAI market share</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">$<span class="counter" data-target="1.9">0</span>B</div>
                        <div class="stat-label">Total ecosystem value</div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">This marks the first clear productization beyond general chatbot interfaces.</p>
            </div>
        </div>

        <!-- Slide 5: Reasoning Capabilities -->
        <div class="slide slide-5" data-slide="5">
            <div class="slide-content">
                <h1 class="slide-title">From Instant to Iterative</h1>
                <p class="slide-description">2025 marked a shift from single-pass inference to multi-step reasoning architectures.</p>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>Chain-of-thought prompting</strong>
                        <p>Moved from research to production</p>
                    </li>
                    <li class="feature-item">
                        <strong>Extended thinking modes</strong>
                        <p>16K-64K token reasoning chains</p>
                    </li>
                    <li class="feature-item">
                        <strong>Self-verification loops</strong>
                        <p>Reflection and iterative improvement</p>
                    </li>
                    <li class="feature-item">
                        <strong>Production models</strong>
                        <p>OpenAI o1 series, Gemini Deep Think, Claude's thinking mode</p>
                    </li>
                </ul>
                <p class="slide-description" style="margin-top: 2rem;">Improved performance on complex problem-solving at the cost of increased latency and compute.</p>
            </div>
        </div>

        <!-- Slide 6: Multimodal Integration -->
        <div class="slide slide-6" data-slide="6">
            <div class="slide-content">
                <h1 class="slide-title">Beyond Text Processing</h1>
                <p class="slide-description">Native multimodal processing became standard across frontier models.</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="20">0</span>B</div>
                        <div class="stat-label">Visual searches monthly (Google Lens)</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="20">0</span>%</div>
                        <div class="stat-label">Shopping-related searches</div>
                    </div>
                </div>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>Vision:</strong> Image understanding, chart/diagram analysis
                    </li>
                    <li class="feature-item">
                        <strong>Audio:</strong> Voice mode with conversational latency
                    </li>
                    <li class="feature-item">
                        <strong>Video:</strong> Processing hours of video content (MMCTAgent architecture)
                    </li>
                    <li class="feature-item">
                        <strong>Cross-modal:</strong> Unified input/output across text, image, audio, video
                    </li>
                </ul>
            </div>
        </div>

        <!-- Slide 7: Open Source Developments -->
        <div class="slide slide-7" data-slide="7">
            <div class="slide-content">
                <h1 class="slide-title">The Open Weight Movement</h1>
                <p class="slide-description">Open source models continued closing the capability gap with proprietary systems.</p>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>Meta Llama 4</strong> - Scout: 10M tokens, Maverick: multimodal
                    </li>
                    <li class="feature-item">
                        <strong>DeepSeek R1</strong> - Reasoning models
                    </li>
                    <li class="feature-item">
                        <strong>Mistral Mixtral 8x22B</strong> - MoE architecture
                    </li>
                    <li class="feature-item">
                        <strong>OpenAI GPT-OSS</strong> - First open-weight release from OpenAI
                    </li>
                </ul>
                <div class="progress-container" style="margin-top: 3rem;">
                    <div class="progress-label">Open Source Market Share</div>
                    <div class="progress-bar-wrapper">
                        <div class="progress-bar" data-progress="13"></div>
                    </div>
                    <p class="slide-description" style="font-size: 0.9rem; margin-top: 1rem;">13% of AI workloads (down from 19% six months prior)</p>
                </div>
            </div>
        </div>

        <!-- Slide 8: Context Window Expansion -->
        <div class="slide slide-8" data-slide="8">
            <div class="slide-content">
                <h1 class="slide-title">Scaling Input Capacity</h1>
                <p class="slide-description">Context windows grew by orders of magnitude</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="10">0</span>M</div>
                        <div class="stat-label">Llama 4 Scout tokens</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="1">0</span>M</div>
                        <div class="stat-label">Gemini 2.5 Pro tokens</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="200">0</span>K</div>
                        <div class="stat-label">Claude tokens</div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">This enables processing entire codebases, lengthy documents, and multi-session conversations without summarization loss.</p>
            </div>
        </div>

        <!-- Slide 9: Enterprise Adoption Patterns -->
        <div class="slide slide-9" data-slide="9">
            <div class="slide-content">
                <h1 class="slide-title">Deployment Realities</h1>
                <p class="slide-description">McKinsey survey data reveals uneven progress</p>
                <div class="progress-container">
                    <div class="progress-label">Organizations using AI</div>
                    <div class="progress-bar-wrapper">
                        <div class="progress-bar" data-progress="88"></div>
                    </div>
                </div>
                <div class="progress-container">
                    <div class="progress-label">AI enables innovation</div>
                    <div class="progress-bar-wrapper">
                        <div class="progress-bar" data-progress="64"></div>
                    </div>
                </div>
                <div class="progress-container">
                    <div class="progress-label">Enterprise-level EBIT impact</div>
                    <div class="progress-bar-wrapper">
                        <div class="progress-bar" data-progress="39"></div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">Transition from proof-of-concept to enterprise-wide deployment continues to be the primary bottleneck.</p>
            </div>
        </div>

        <!-- Slide 10: Cost Efficiency Trends -->
        <div class="slide slide-10" data-slide="10">
            <div class="slide-content">
                <h1 class="slide-title">Economics of Model Training</h1>
                <p class="slide-description">Training costs showed significant variance</p>
                <div class="stat-card" style="max-width: 600px; margin: 2rem auto;">
                    <div class="stat-number pulse">DeepSeek V3</div>
                    <div class="stat-label" style="font-size: 1.2rem; margin-top: 1rem;">
                        <strong>685B parameters</strong> (37B active via MoE)<br>
                        Training cost: <strong>$5.5M</strong><br>
                        2.788M GPU hours on H800s<br>
                        Competitive performance with models costing 10x more
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">Architecture choices (MoE, efficient attention) can dramatically reduce training economics while maintaining capability.</p>
            </div>
        </div>

        <!-- Slide 11: Model Context Protocol -->
        <div class="slide slide-11" data-slide="11">
            <div class="slide-content">
                <h1 class="slide-title">Standardization Efforts</h1>
                <p class="slide-description">2025 saw the emergence of protocols for agent interoperability</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">MCP</div>
                        <div class="stat-label">Model Context Protocol<br>Anthropic-initiated standard<br>for AI-to-system integration</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">A2A</div>
                        <div class="stat-label">Agent-to-Agent Protocol<br>Emerging standard<br>for multi-agent coordination</div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">These represent infrastructure necessary for production agentic systems.</p>
            </div>
        </div>

        <!-- Slide 12: Limitations and Challenges -->
        <div class="slide slide-12" data-slide="12">
            <div class="slide-content">
                <h1 class="slide-title">Persistent Issues</h1>
                <p class="slide-description">Despite advances, fundamental challenges remain</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">Technical</div>
                        <div class="stat-label" style="text-align: left; line-height: 1.8;">
                            â€¢ "Black box" decision-making<br>
                            â€¢ Hallucination rates improved but not eliminated<br>
                            â€¢ Reasoning still brittle on edge cases<br>
                            â€¢ Energy consumption at scale
                        </div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">Organizational</div>
                        <div class="stat-label" style="text-align: left; line-height: 1.8;">
                            â€¢ ROI measurement remains difficult<br>
                            â€¢ Change management for AI integration<br>
                            â€¢ Data governance and privacy concerns<br>
                            â€¢ Skill gaps in implementation teams
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 13: Video Generation Maturity -->
        <div class="slide slide-13" data-slide="13">
            <div class="slide-content">
                <h1 class="slide-title">Text-to-Video Progress</h1>
                <p class="slide-description">Video generation moved from research demos to production tools</p>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>OpenAI Sora</strong> - General release
                    </li>
                    <li class="feature-item">
                        <strong>Google Veo</strong> - Integrated with Gemini
                    </li>
                    <li class="feature-item">
                        <strong>Runway Gen-2</strong> - Commercial deployment
                    </li>
                    <li class="feature-item">
                        <strong>Kling O1</strong> - Unified multimodal creation, solved character consistency
                    </li>
                </ul>
                <p class="slide-description" style="margin-top: 2rem;">60-second 4K generation, improved temporal consistency, character/scene persistence across frames.</p>
            </div>
        </div>

        <!-- Slide 14: Voice Interface Evolution -->
        <div class="slide slide-14" data-slide="14">
            <div class="slide-content">
                <h1 class="slide-title">Conversational AI Audio</h1>
                <p class="slide-description">Voice capabilities advanced beyond text-to-speech</p>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>Real-time conversational latency</strong> - Sub-second response
                    </li>
                    <li class="feature-item">
                        <strong>Emotional tone modulation</strong> - Natural expression
                    </li>
                    <li class="feature-item">
                        <strong>Mid-utterance interruption</strong> - Human-like interaction
                    </li>
                    <li class="feature-item">
                        <strong>Multi-turn conversation</strong> - Context retention
                    </li>
                </ul>
                <p class="slide-description" style="margin-top: 2rem;">Applications: Customer support automation, accessibility tools, language learning</p>
            </div>
        </div>

        <!-- Slide 15: Small Language Models -->
        <div class="slide slide-15" data-slide="15">
            <div class="slide-content">
                <h1 class="slide-title">Efficiency-Focused Development</h1>
                <p class="slide-description">2025 saw increased focus on smaller, specialized models</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="100">0</span>+</div>
                        <div class="stat-label">Tokens/second on device</div>
                    </div>
                </div>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>On-device models</strong> - Phones, laptops (Gemma 3n, Microsoft Mu)
                    </li>
                    <li class="feature-item">
                        <strong>NPU-optimized inference</strong> - Edge computing
                    </li>
                    <li class="feature-item">
                        <strong>Privacy-preserving</strong> - Local deployment
                    </li>
                    <li class="feature-item">
                        <strong>Domain-specific</strong> - Fine-tuning
                    </li>
                </ul>
                <p class="slide-description" style="margin-top: 2rem;">A counter-trend to "bigger is better," driven by edge computing, privacy requirements, and cost optimization.</p>
            </div>
        </div>

        <!-- Slide 16: Benchmark Evolution -->
        <div class="slide slide-16" data-slide="16">
            <div class="slide-content">
                <h1 class="slide-title">Performance Measurement</h1>
                <p class="slide-description">New benchmarks emerged to test advanced capabilities</p>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>Humanity's Last Exam</strong> - Reasoning under open-ended conditions
                    </li>
                    <li class="feature-item">
                        <strong>GPQA Diamond</strong> - Complex question accuracy
                    </li>
                    <li class="feature-item">
                        <strong>SWE-bench</strong> - Software engineering problem-solving
                    </li>
                    <li class="feature-item">
                        <strong>Video-MME</strong> - Multimodal video understanding
                    </li>
                </ul>
                <p class="slide-description" style="margin-top: 2rem;">As models saturate traditional benchmarks, evaluation frameworks continue evolving to test emerging capabilities.</p>
            </div>
        </div>

        <!-- Slide 17: Market Projections vs. Reality -->
        <div class="slide slide-17" data-slide="17">
            <div class="slide-content">
                <h1 class="slide-title">Hype Calibration</h1>
                <p class="slide-description">Industry predictions showed typical technology adoption patterns</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number">$<span class="counter" data-target="5.1">0</span>B</div>
                        <div class="stat-label">AI agent market (2024)</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number">$<span class="counter" data-target="47.1">0</span>B</div>
                        <div class="stat-label">Projected (2030)</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number"><span class="counter" data-target="44.8">0</span>%</div>
                        <div class="stat-label">CAGR</div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 2rem;">Gartner positioned AI agents at "Peak of Inflated Expectations" - Classic Gartner Hype Cycle dynamics in action.</p>
            </div>
        </div>

        <!-- Slide 18: Physical AI Development -->
        <div class="slide slide-18" data-slide="18">
            <div class="slide-content">
                <h1 class="slide-title">Embodied Intelligence</h1>
                <p class="slide-description">2025 saw early work on robotics integration</p>
                <ul class="feature-list">
                    <li class="feature-item">
                        <strong>Google Gemini Robotics On-Device</strong> - VLA models
                    </li>
                    <li class="feature-item">
                        <strong>Vision-language-action models</strong> - Optimized for edge deployment
                    </li>
                    <li class="feature-item">
                        <strong>Real-world sensor data</strong> - LIDAR, GPS, video integration
                    </li>
                </ul>
                <p class="slide-description" style="margin-top: 2rem;">This represents a research direction rather than deployed capability, but signals the next frontier beyond purely digital agents.</p>
            </div>
        </div>

        <!-- Slide 19: Key Takeaways -->
        <div class="slide slide-19" data-slide="19">
            <div class="slide-content">
                <h1 class="slide-title">What 2025 Demonstrated</h1>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">Technical Progress</div>
                        <div class="stat-label" style="text-align: left; line-height: 1.8;">
                            â€¢ Reasoning capabilities improved<br>
                            â€¢ Multimodal processing standard<br>
                            â€¢ Context windows scaled<br>
                            â€¢ Code generation reached PMF
                        </div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">Deployment Gap</div>
                        <div class="stat-label" style="text-align: left; line-height: 1.8;">
                            â€¢ Experimentation exceeds deployment<br>
                            â€¢ Enterprise-wide scaling challenging<br>
                            â€¢ Human oversight essential<br>
                            â€¢ ROI measurement evolving
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Slide 20: 2026 Outlook -->
        <div class="slide slide-20" data-slide="20">
            <div class="slide-content">
                <h1 class="slide-title">2026 Outlook</h1>
                <p class="slide-description">Based on current trajectories</p>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">Likely</div>
                        <div class="stat-label" style="text-align: left; line-height: 1.8;">
                            â€¢ Agentic workflow refinement<br>
                            â€¢ Further multimodal integration<br>
                            â€¢ More efficient training methods<br>
                            â€¢ Expanded vertical applications
                        </div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-number" style="font-size: 2rem;">Uncertain</div>
                        <div class="stat-label" style="text-align: left; line-height: 1.8;">
                            â€¢ Enterprise-wide deployment acceleration<br>
                            â€¢ Novel capability breakthroughs<br>
                            â€¢ Regulatory framework development<br>
                            â€¢ Open vs. proprietary dynamics
                        </div>
                    </div>
                </div>
                <p class="slide-description" style="margin-top: 3rem; font-size: 1.5rem; font-weight: 600;">The industry remains in rapid evolution with uncertain convergence points.</p>
                <p class="slide-description" style="margin-top: 3rem; font-size: 1rem; font-weight: 600;">My small take: it's not clear that the industry will converge on a single model or architecture. The most likely outcome is a continued diversity of models and architectures, each with its own strengths and weaknesses. This is a good thing, as it will allow for more experimentation and innovation. However, it will also make it more difficult to compare models and architectures, and to understand the trade-offs between them. This is why we need more benchmarks and more standardized evaluation frameworks.</p>
            </div>
        </div>
        
        <!-- References Section -->
        <section class="references-section">
            <div class="references-content">
                <h1 class="references-title">References</h1>
                
                <div class="references-category">
                    <h2 class="category-title">Survey Data & Market Research</h2>
                    
                    <div class="reference-item">
                        <div class="reference-source">IBM and Morning Consult Developer Survey</div>
                        <div class="reference-details">
                            IBM. (2025). "AI Agents in 2025: Expectations vs. Reality." IBM Think Insights.
                        </div>
                        <a href="https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality" target="_blank" rel="noopener" class="reference-link">https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality</a>
                        <div class="reference-key-data">Key data: 99% of enterprise developers exploring AI agents, agent adoption patterns</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">McKinsey Global Survey on AI</div>
                        <div class="reference-details">
                            McKinsey & Company. (2025). "The state of AI in 2025: Agents, innovation, and transformation."
                        </div>
                        <a href="https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai" target="_blank" rel="noopener" class="reference-link">https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai</a>
                        <div class="reference-key-data">Survey period: June 25 - July 29, 2025 | Sample: 1,993 participants across 105 nations | Key data: 88% AI adoption, 62% experimenting with agents, 23% scaling agents, 39% reporting EBIT impact</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Menlo Ventures LLM Market Update</div>
                        <div class="reference-details">
                            Menlo Ventures. (2025). "2025 Mid-Year LLM Market Update: Foundation Model Landscape + Economics."
                        </div>
                        <a href="https://menlovc.com/perspective/2025-mid-year-llm-market-update/" target="_blank" rel="noopener" class="reference-link">https://menlovc.com/perspective/2025-mid-year-llm-market-update/</a>
                        <div class="reference-key-data">Survey: 150 technical decision-makers at enterprises and startups (June 30 - July 10, 2025) | Key data: Claude 42% code generation market share, OpenAI 21%, $1.9B coding ecosystem, 13% open-source workload share</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Gartner Research</div>
                        <div class="reference-details">
                            Gartner, Inc. (2025). "Gartner Hype Cycle for Artificial Intelligence, 2025."
                        </div>
                        <a href="https://www.gartner.com/en/newsroom/press-releases/2025-08-05-gartner-hype-cycle-identifies-top-ai-innovations-in-2025" target="_blank" rel="noopener" class="reference-link">https://www.gartner.com/en/newsroom/press-releases/2025-08-05-gartner-hype-cycle-identifies-top-ai-innovations-in-2025</a>
                        <div class="reference-key-data">Key insight: AI agents and AI-ready data at "Peak of Inflated Expectations"</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">MarketsandMarkets Projection</div>
                        <div class="reference-details">
                            Cited in: Alvarez & Marsal. (2025). "Demystifying AI Agents in 2025: Separating Hype From Reality and Navigating Market Outlook."
                        </div>
                        <a href="https://www.alvarezandmarsal.com/thought-leadership/demystifying-ai-agents-in-2025-separating-hype-from-reality-and-navigating-market-outlook" target="_blank" rel="noopener" class="reference-link">https://www.alvarezandmarsal.com/thought-leadership/demystifying-ai-agents-in-2025-separating-hype-from-reality-and-navigating-market-outlook</a>
                        <div class="reference-key-data">Projection: AI agent market from $5.1B (2024) to $47.1B (2030), 44.8% CAGR</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Capgemini Research</div>
                        <div class="reference-details">
                            Cited in: Collabnix. (2025). "Agentic AI Trends 2025: The Complete Guide to Autonomous Intelligence Revolution."
                        </div>
                        <a href="https://collabnix.com/agentic-ai-trends-2025-the-complete-guide-to-autonomous-intelligence-revolution/" target="_blank" rel="noopener" class="reference-link">https://collabnix.com/agentic-ai-trends-2025-the-complete-guide-to-autonomous-intelligence-revolution/</a>
                        <div class="reference-key-data">Key data: 82% of organizations plan AI agent integration by 2026</div>
                    </div>
                </div>
                
                <div class="references-category">
                    <h2 class="category-title">Model Releases & Technical Documentation</h2>
                    
                    <div class="reference-item">
                        <div class="reference-source">Anthropic - Claude Models</div>
                        <div class="reference-details">
                            Anthropic. (2024-2025). Claude 3.5 Sonnet, Claude 3.7 Sonnet, Claude 4 family releases. Source: Menlo Ventures report references February 2025 Claude 3.7 Sonnet release.
                        </div>
                        <div class="reference-key-data">Key features: Extended thinking, MCP integration, agent-first design</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">OpenAI - GPT-5 Series</div>
                        <div class="reference-details">
                            Multiple sources reference August 2025 GPT-5 release. InfoQ. (2025). "InfoQ AI, ML and Data Engineering Trends Report - 2025."
                        </div>
                        <a href="https://www.infoq.com/articles/ai-ml-data-engineering-trends-2025/" target="_blank" rel="noopener" class="reference-link">https://www.infoq.com/articles/ai-ml-data-engineering-trends-2025/</a>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Google - Gemini Models</div>
                        <div class="reference-details">
                            TechTarget. (2025). "30 of the best large language models in 2026." Splunk. (2025). "Top LLMs To Use in 2026: Our Best Picks."
                        </div>
                        <a href="https://www.splunk.com/en_us/blog/learn/llms-best-to-use.html" target="_blank" rel="noopener" class="reference-link">https://www.splunk.com/en_us/blog/learn/llms-best-to-use.html</a>
                        <div class="reference-key-data">Key data: Gemini 2.5 Pro (March 2025) with Deep Think mode, 1M token context; Gemini 3 Pro (November 2025)</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Meta - Llama 4</div>
                        <div class="reference-details">
                            Shakudo. (2025). "Top 9 Large Language Models as of December 2025."
                        </div>
                        <a href="https://www.shakudo.io/blog/top-9-large-language-models" target="_blank" rel="noopener" class="reference-link">https://www.shakudo.io/blog/top-9-large-language-models</a>
                        <div class="reference-key-data">Key features: Llama 4 Scout with 10M token context window, multimodal capabilities</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">DeepSeek Models</div>
                        <div class="reference-details">
                            Multiple sources document DeepSeek V3 and V3.1. Splunk report: DeepSeek-V3-0324 launched March 24, 2025.
                        </div>
                        <div class="reference-key-data">Key data: 685B parameters (37B active), $5.5M training cost, 2.788M GPU hours on H800s. DeepSeek V3.1 (August 2025) with hybrid thinking/non-thinking modes</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">xAI - Grok 4</div>
                        <div class="reference-details">
                            Medium (2025) report: Grok 4 launched July 2025.
                        </div>
                        <div class="reference-key-data">Performance: Comparable SWE-bench to GPT-5 and Claude Opus 4.1</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Mistral AI</div>
                        <div class="reference-details">
                            Shakudo report documents Mixtral 8x22B with Mixture-of-Experts architecture.
                        </div>
                        <div class="reference-key-data">Apache 2.0 license, open-source availability</div>
                    </div>
                </div>
                
                <div class="references-category">
                    <h2 class="category-title">Multimodal & Video Generation</h2>
                    
                    <div class="reference-item">
                        <div class="reference-source">Google Lens Data</div>
                        <div class="reference-details">
                            Lumar. (2025). "Multimodal Search in 2025: Image, Video, & Voice Search."
                        </div>
                        <a href="https://www.lumar.io/blog/industry-news/multimodal-search-video-image-and-voice-search/" target="_blank" rel="noopener" class="reference-link">https://www.lumar.io/blog/industry-news/multimodal-search-video-image-and-voice-search/</a>
                        <div class="reference-key-data">Key data: 20 billion visual searches monthly, 20% shopping-related, fastest growing among 18-24 age group</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Kling O1 Video Model</div>
                        <div class="reference-details">
                            Morningstar. (2025). "Kling O1 Launches as the World's First Unified Multimodal Video Model." Announcement: December 1, 2025.
                        </div>
                        <div class="reference-key-data">Features: Unified multimodal creation tool, character consistency</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Runway Gen-2</div>
                        <div class="reference-details">
                            Runway Research. "Gen-2: Generate novel videos with text, images or video clips."
                        </div>
                        <a href="https://runwayml.com/research/gen-2" target="_blank" rel="noopener" class="reference-link">https://runwayml.com/research/gen-2</a>
                        <div class="reference-key-data">Capabilities: Text-to-video, image-to-video generation</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Microsoft Research - MMCTAgent</div>
                        <div class="reference-details">
                            Microsoft Research. (2025). "MMCTAgent: Enabling multimodal reasoning over large video and image collections." Published: November 12, 2025.
                        </div>
                        <a href="https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/" target="_blank" rel="noopener" class="reference-link">https://www.microsoft.com/en-us/research/blog/mmctagent-enabling-multimodal-reasoning-over-large-video-and-image-collections/</a>
                        <div class="reference-key-data">Architecture: Multi-modal Critical Thinking Agent for long-form video reasoning</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">General Multimodal AI Overview</div>
                        <div class="reference-details">
                            Medium. (2025). "Multimodal AI in 2025: Integrating Text, Image, Audio, and Video for Smarter AI." Aya Data. (2025). "Multimodal AI: Breaking Down Barriers Between Text, Image, Audio and Video."
                        </div>
                        <a href="https://www.ayadata.ai/multimodal-ai-breaking-down-barriers-between-text-image-audio-and-video/" target="_blank" rel="noopener" class="reference-link">https://www.ayadata.ai/multimodal-ai-breaking-down-barriers-between-text-image-audio-and-video/</a>
                    </div>
                </div>
                
                <div class="references-category">
                    <h2 class="category-title">Industry Analysis & Trends</h2>
                    
                    <div class="reference-item">
                        <div class="reference-source">Microsoft AI Trends</div>
                        <div class="reference-details">
                            Microsoft. (2025). "6 AI trends you'll see more of in 2025." Published: May 1, 2025.
                        </div>
                        <a href="https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/" target="_blank" rel="noopener" class="reference-link">https://news.microsoft.com/source/features/ai/6-ai-trends-youll-see-more-of-in-2025/</a>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">MIT Technology Review</div>
                        <div class="reference-details">
                            MIT Technology Review. (2025). "What's next for AI in 2025." Published: January 24, 2025.
                        </div>
                        <a href="https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/" target="_blank" rel="noopener" class="reference-link">https://www.technologyreview.com/2025/01/08/1109188/whats-next-for-ai-in-2025/</a>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Morgan Stanley Technology Analysis</div>
                        <div class="reference-details">
                            Morgan Stanley. (2025). "5 AI Trends Shaping Innovation and ROI in 2025."
                        </div>
                        <a href="https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt" target="_blank" rel="noopener" class="reference-link">https://www.morganstanley.com/insights/articles/ai-trends-reasoning-frontier-models-2025-tmt</a>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">InfoQ Trends Report</div>
                        <div class="reference-details">
                            InfoQ. (2025). "InfoQ AI, ML and Data Engineering Trends Report - 2025." Published: September 24, 2025.
                        </div>
                        <a href="https://www.infoq.com/articles/ai-ml-data-engineering-trends-2025/" target="_blank" rel="noopener" class="reference-link">https://www.infoq.com/articles/ai-ml-data-engineering-trends-2025/</a>
                        <div class="reference-key-data">Topics: Reasoning models, AI DevOps, Physical AI, Model Context Protocol</div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">MarkTechPost Analysis</div>
                        <div class="reference-details">
                            MarkTechPost. (2025). "AI Agent Trends of 2025: A Transformative Landscape." Published: August 10, 2025.
                        </div>
                        <a href="https://www.marktechpost.com/2025/08/10/ai-agent-trends-of-2025-a-transformative-landscape/" target="_blank" rel="noopener" class="reference-link">https://www.marktechpost.com/2025/08/10/ai-agent-trends-of-2025-a-transformative-landscape/</a>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">AIwire LLM Roundup</div>
                        <div class="reference-details">
                            AIwire. (2025). "LLM Roundup: A Wave of New Releases Winds Down the Year." Published: November 25, 2025.
                        </div>
                        <a href="https://www.hpcwire.com/aiwire/2025/11/25/llm-roundup-a-wave-of-new-releases-winds-down-the-year/" target="_blank" rel="noopener" class="reference-link">https://www.hpcwire.com/aiwire/2025/11/25/llm-roundup-a-wave-of-new-releases-winds-down-the-year/</a>
                    </div>
                </div>
                
                <div class="references-category">
                    <h2 class="category-title">Open Source & Local Models</h2>
                    
                    <div class="reference-item">
                        <div class="reference-source">Instaclustr Open Source Guide</div>
                        <div class="reference-details">
                            Instaclustr. (2025). "Top 10 open source LLMs for 2025." Published: October 29, 2025.
                        </div>
                        <a href="https://www.instaclustr.com/education/open-source-ai/top-10-open-source-llms-for-2025/" target="_blank" rel="noopener" class="reference-link">https://www.instaclustr.com/education/open-source-ai/top-10-open-source-llms-for-2025/</a>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Pinggy Local LLM Tools</div>
                        <div class="reference-details">
                            Pinggy. (2025). "Top 5 Local LLM Tools and Models in 2025." Published: June 4, 2025.
                        </div>
                        <a href="https://pinggy.io/blog/top_5_local_llm_tools_and_models_2025/" target="_blank" rel="noopener" class="reference-link">https://pinggy.io/blog/top_5_local_llm_tools_and_models_2025/</a>
                        <div class="reference-key-data">Coverage: OpenAI GPT-OSS, DeepSeek V3.2-Exp, Qwen models, Llama 4, Gemma 3</div>
                    </div>
                </div>
                
                <div class="references-category">
                    <h2 class="category-title">Additional Technical Resources</h2>
                    
                    <div class="reference-item">
                        <div class="reference-source">Global Market Insights</div>
                        <div class="reference-details">
                            Cited in Aya Data article. Multimodal AI market valuation: $1.6B (2024), projected 32.7% CAGR through 2034.
                        </div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">AWS Agent Investment</div>
                        <div class="reference-details">
                            Cited in Alvarez & Marsal article. Reuters reporting on AWS doubling down on AI agents with new business unit.
                        </div>
                    </div>
                    
                    <div class="reference-item">
                        <div class="reference-source">Simon Willison - LLM Tool Development</div>
                        <div class="reference-details">
                            Willison, S. (2025). Various LLM tool release notes.
                        </div>
                        <a href="https://simonwillison.net/series/llm-releases/" target="_blank" rel="noopener" class="reference-link">https://simonwillison.net/series/llm-releases/</a>
                        <div class="reference-key-data">Coverage of GPT-5, tool usage, structured outputs</div>
                    </div>
                </div>
                
                <div class="reference-note">
                    <div class="reference-note-title">Notes on Data Currency</div>
                    <div class="reference-note-text">
                        All data reflects information available through early December 2025. Survey data collection periods are noted where available. Market projections represent industry analyst forecasts and should be interpreted as forward-looking estimates rather than guaranteed outcomes.
                        <br><br>
                        The "December 2025" timeframe for this analysis means some Q4 2025 developments may still be emerging, and complete year-end data may not yet be available for all metrics cited.
                    </div>
                </div>
            </div>
        </section>
    </div>

    <script src="../../js/interactive-bg.js"></script>
    <script src="../../js/theme-switcher.js"></script>
    <script src="../../js/main.js"></script>
    <script>

        // Scroll progress indicator
        function updateScrollProgress() {
            const scrollProgress = document.getElementById('scrollProgress');
            const windowHeight = window.innerHeight;
            const documentHeight = document.documentElement.scrollHeight;
            const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
            const scrollPercent = (scrollTop / (documentHeight - windowHeight)) * 100;
            scrollProgress.style.width = scrollPercent + '%';
        }

        window.addEventListener('scroll', updateScrollProgress);
        window.addEventListener('resize', updateScrollProgress);

        // Intersection Observer for animations
        const observerOptions = {
            threshold: 0.3,
            rootMargin: '0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    const slide = entry.target;
                    
                    // Animate counters
                    const counters = slide.querySelectorAll('.counter');
                    counters.forEach(counter => {
                        if (counter.dataset.animated !== 'true') {
                            counter.dataset.animated = 'true';
                            const target = parseFloat(counter.getAttribute('data-target'));
                            const duration = 2000;
                            const increment = target / (duration / 16);
                            let current = 0;
                            
                            const updateCounter = () => {
                                current += increment;
                                if (current < target) {
                                    counter.textContent = Math.floor(current);
                                    requestAnimationFrame(updateCounter);
                                } else {
                                    counter.textContent = target;
                                }
                            };
                            updateCounter();
                        }
                    });
                    
                    // Animate progress bars
                    const progressBars = slide.querySelectorAll('.progress-bar');
                    progressBars.forEach(bar => {
                        if (bar.dataset.animated !== 'true') {
                            bar.dataset.animated = 'true';
                            const progress = bar.getAttribute('data-progress');
                            setTimeout(() => {
                                bar.style.width = progress + '%';
                            }, 300);
                        }
                    });
                }
            });
        }, observerOptions);

        // Observe all slides
        document.querySelectorAll('.slide').forEach(slide => {
            observer.observe(slide);
        });

        // Initial scroll progress update
        updateScrollProgress();
        
        // Create floating particles for each slide and references section
        function createSlideParticles() {
            const slides = document.querySelectorAll('.slide, .references-section');
            slides.forEach((slide, slideIndex) => {
                // Create 8-12 particles per slide
                const particleCount = 8 + Math.floor(Math.random() * 5);
                for (let i = 0; i < particleCount; i++) {
                    const particle = document.createElement('div');
                    const particleType = Math.floor(Math.random() * 3) + 1;
                    particle.className = `slide-particle particle-${particleType}`;
                    
                    // Random starting position
                    particle.style.left = Math.random() * 100 + '%';
                    particle.style.top = Math.random() * 100 + '%';
                    
                    // Random delay for staggered animation
                    particle.style.animationDelay = Math.random() * 5 + 's';
                    particle.style.animationDuration = (12 + Math.random() * 8) + 's';
                    
                    slide.appendChild(particle);
                }
            });
        }
        
        // Initialize particles when DOM is ready
        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', createSlideParticles);
        } else {
            createSlideParticles();
        }
    </script>
    <script src="../../js/interactive-bg.js"></script>
    <script src="../../js/theme-switcher.js"></script>
    <script src="../../js/main.js"></script>
</body>
</html>

